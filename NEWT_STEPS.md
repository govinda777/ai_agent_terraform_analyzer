# New Steps for AI Agent Terraform Analyzer

## Overview
This document outlines the steps and best practices for implementing, testing, and deploying changes in the AI Agent Terraform Analyzer project. It provides a clear, step-by-step guide to ensure consistency and quality in the codebase.

## Step 1: Requirements Gathering
- Review all relevant project documentation and context.
- Identify dependencies, configuration details, and open tasks that may affect the implementation.

## Step 2: Clarification and Planning
- Clarify ambiguous requirements with stakeholders.
- Plan the implementation steps, including file modifications, testing, and verification.
- Consult related documentation (e.g., AGENT.md, PROMPT_BUILDER.md, REINFORCEMENT_LEARNING.md) for additional context and guidelines.

## Step 3: Implementation
- Execute code changes using tools (e.g., file_editor) while adhering to coding standards.
- Use precise commit messages to document changes.
- Ensure that modifications are based on the latest file versions and project context.

## Step 4: Verification and Testing
- Run tests and verify that the changes meet the desired outcomes.
- Confirm that no linting or diagnostics errors occur post-implementation.
- Iterate based on testing feedback to refine changes.

## Step 5: Documentation and Continuous Improvement
- Update this document as new steps or modifications are introduced.
- Gather feedback from team members and stakeholders to continuously improve the development process.
- Maintain clear and detailed documentation to support future development and troubleshooting.

## Additional Resources
- AGENT.md
- PROMPT_BUILDER.md
- REINFORCEMENT_LEARNING.md
- TRAINING_ALGORITHM.md
- README.md

## Conclusion
Adhering to these steps ensures a systematic approach to development, quality assurance, and continuous improvement within the AI Agent Terraform Analyzer project. Clear documentation is essential for long-term project success and effective collaboration.